{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "data: 2024-04-01\n",
    "title: Resolution Proving I\n",
    "---\n",
    "\n",
    "Not an april fools post.\n",
    "\n",
    "One of my favorite projects is [PyRes](https://github.com/eprover/PyRes). It's a pedagogical first order prover in python. This blog post is mostly a compression and repetition of some of what is found there.\n",
    "\n",
    "[Resolution](https://en.wikipedia.org/wiki/Resolution_(logic)) theorem proving is an old and popular style of theorem prover.\n",
    "\n",
    "It basically takes in a pile of syntactic facts and smashes them together producing new facts. That sentence also describe the entirety of \"logic\".\n",
    "\n",
    "First we need a basic term datatype. I kind of like using python dataclasses. This is the analog of a algebraic datatype `type term = Var of string | Fn of string * term list`. Variables can be used to represent an implicit \"forall\" character of a proven or asserted fact/clause.\n",
    "They sometimes play a dual role as the things searched for in a query (when inside a prolog query for example). These are quite different uses/modalities and it can be good to be aware of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "@dataclass(frozen=True)\n",
    "class Term():\n",
    "    pass\n",
    "@dataclass(frozen=True)\n",
    "class Fn(Term):\n",
    "    name: str\n",
    "    args: tuple[Any, ...] = ()\n",
    "    def __repr__(self):\n",
    "        if len(self.args) == 0:\n",
    "            return self.name\n",
    "        return f\"{self.name}({', '.join(map(repr, self.args))})\"\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class Var(Term):\n",
    "    name: str\n",
    "    def __repr__(self):\n",
    "        return \"?\" + self.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to substitute in terms for variables. A substitution dictionary is a mapping from variable names to terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subst(t : Term, s : dict[str,Term]):\n",
    "    match t:\n",
    "        case Var(name):\n",
    "            return s.get(name, t)\n",
    "        case Fn(name, args):\n",
    "            return Fn(name, [subst(arg, s) for arg in args])\n",
    "        case _:\n",
    "            raise ValueError(\"Invalid term\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Unification](https://en.wikipedia.org/wiki/Unification_(computer_science)) is like two way pattern matching. It can also be thought of as a most basic form of equation solving.\n",
    "\n",
    "Unification is tricky, as are many things having to do with variables so I try to follow some reference pretty closely.\n",
    "\n",
    "The basic idea is pretty simple. You take two terms. If they are concrete constants, they better match. If so, recurse on the arguments.\n",
    "If one is a variable, you have sort of solved that equation. Substitute that expression for that variable everywhere.\n",
    "The [occurs check](https://en.wikipedia.org/wiki/Occurs_check) is an interesting subtlety. It is sort of making sure you don't allow equations like `X = cons(1, X)` to be solvable. Unless you realize you're up to something weird, it is probably what you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mgu(f(x), g(x))=None\n",
      "mgu(f(x), f(y))={'x': ?y}\n",
      "mgu(f(x), f(x))={}\n",
      "mgu(f(x), f(f(x)))=None\n",
      "mgu(f(x), f(f(y)))={'x': f(?y)}\n"
     ]
    }
   ],
   "source": [
    "def occurs_check(x : Var, t : Term):\n",
    "    if isinstance(t, Var):\n",
    "        return x.name == t.name\n",
    "    elif isinstance(t, Fn):\n",
    "        return any(occurs_check(x, arg) for arg in t.args)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid term\")\n",
    "\n",
    "# https://github.com/eprover/PyRes/blob/master/unification.py\n",
    "def mgu(t1:Term, t2:Term):\n",
    "    l1 = [t1]\n",
    "    l2 = [t2]\n",
    "    s = {}\n",
    "    while len(l1) != 0:\n",
    "        t1 = l1.pop()\n",
    "        t2 = l2.pop()\n",
    "        if isinstance(t1, Var):\n",
    "            if t1 == t2:\n",
    "                continue\n",
    "            if occurs_check(t1, t2):\n",
    "                return None\n",
    "            l1 = [subst(t, {t1.name:t2}) for t in l1]\n",
    "            l2 = [subst(t, {t1.name:t2}) for t in l2]\n",
    "            s[t1.name] = t2\n",
    "        elif isinstance(t2, Var):\n",
    "            if occurs_check(t2, t1):\n",
    "                return None\n",
    "            l1 = [subst(t, {t2.name:t1}) for t in l1]\n",
    "            l2 = [subst(t, {t2.name:t1}) for t in l2]\n",
    "            s[t2.name] = t1\n",
    "        elif isinstance(t1, Fn) and isinstance(t2, Fn):\n",
    "            if t1.name != t2.name or len(t1.args) != len(t2.args):\n",
    "                return None\n",
    "            l1.extend(t1.args)\n",
    "            l2.extend(t2.args)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term\")\n",
    "    return s\n",
    "\n",
    "def test():\n",
    "    x,y = Var(\"x\"), Var(\"y\")\n",
    "    def f(x):\n",
    "        return Fn(\"f\", (x,))\n",
    "    def g(x):\n",
    "        return Fn(\"g\", (x,))\n",
    "    print(f\"{mgu(f(x), g(x))=}\")\n",
    "    print(f\"{mgu(f(x), f(y))=}\")\n",
    "    print(f\"{mgu(f(x), f(x))=}\")\n",
    "    print(f\"{mgu(f(x), f(f(x)))=}\")\n",
    "    print(f\"{mgu(f(x), f(f(y)))=}\")\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clause is a set of negative and positive literals. Negative literals are hypotheses and positive literals are the possible conclusions.\n",
    "A clause is the statement that `not neg[0] or not neg[1] or ... or pos[0] or pos[1] or pos[2] or ... ` is true. It can also be thought of as `(neg[0] and neg[1] and neg[2] ...) => (pos[0] or pos[1] or ...)` or `{neg_i} |- {pos_i}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Clause(): # Sequent\n",
    "    neg: tuple[Term, ...] # frozenset? # hyps\n",
    "    pos: tuple[Term, ...] # concs\n",
    "    def __repr__(self):\n",
    "        return f\"{self.neg} ⊢ {self.pos}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge(x,y):\n",
    "    return Fn(\"edge\", (x,y))\n",
    "def path(x,y):\n",
    "    return Fn(\"path\", (x,y))\n",
    "a,b,c,d = Fn(\"a\"), Fn(\"b\"), Fn(\"c\"), Fn(\"d\")\n",
    "facts = [Clause((), (edge(a,b),)), Clause((), (edge(b,c),)), Clause((), (edge(c,d),))]\n",
    "\n",
    "\n",
    "X,Y,Z = Var(\"X\"), Var(\"Y\"), Var(\"Z\")\n",
    "path_base = Clause([edge(X,Y)], [path(X,Y)])\n",
    "path_trans = Clause([path(X,Y), edge(Y,Z)], [path(X,Z)])\n",
    "clauses = [path_base,path_trans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Resolution](https://en.wikipedia.org/wiki/Resolution_(logic)) is the analog of modus ponens or the cut rule. We take two clauses and see if we can make a positive literal from one to match (unify) a negative from the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact=() ⊢ (edge(a, b),), clause=[edge(?X, ?Y)] ⊢ [path(?X, ?Y)], resolvents=[() ⊢ (path(a, b),)]\n",
      "fact=() ⊢ (edge(a, b),), clause=[path(?X, ?Y), edge(?Y, ?Z)] ⊢ [path(?X, ?Z)], resolvents=[(path(?X, a),) ⊢ (path(?X, b),)]\n",
      "fact=() ⊢ (edge(b, c),), clause=[edge(?X, ?Y)] ⊢ [path(?X, ?Y)], resolvents=[() ⊢ (path(b, c),)]\n",
      "fact=() ⊢ (edge(b, c),), clause=[path(?X, ?Y), edge(?Y, ?Z)] ⊢ [path(?X, ?Z)], resolvents=[(path(?X, b),) ⊢ (path(?X, c),)]\n",
      "fact=() ⊢ (edge(c, d),), clause=[edge(?X, ?Y)] ⊢ [path(?X, ?Y)], resolvents=[() ⊢ (path(c, d),)]\n",
      "fact=() ⊢ (edge(c, d),), clause=[path(?X, ?Y), edge(?Y, ?Z)] ⊢ [path(?X, ?Z)], resolvents=[(path(?X, c),) ⊢ (path(?X, d),)]\n"
     ]
    }
   ],
   "source": [
    "def computeResolvents(clause1: Clause, clause2: Clause):\n",
    "    res = []\n",
    "    # freshen vars?\n",
    "    #fv = freevars(clause2)\n",
    "    #clause1 = freshen_clause(clause1)\n",
    "    for lit1 in clause1.pos:\n",
    "        for lit2 in clause2.neg:\n",
    "            s = mgu(lit1,lit2)\n",
    "            if s == None:\n",
    "                continue\n",
    "            new_clause = Clause(tuple(subst(lit,s) for lit in clause1.neg) + tuple(subst(lit,s) for lit in clause2.neg if lit != lit2), tuple(subst(lit,s) for lit in clause1.pos if lit != lit1) + tuple(subst(lit,s) for lit in clause2.pos))\n",
    "            res.append(new_clause)\n",
    "    return res\n",
    "\n",
    "def test():\n",
    "    # this is a datalog-esque loop\n",
    "    for fact in facts:\n",
    "        for clause in clauses:\n",
    "            resolvents = computeResolvents(fact, clause)\n",
    "            print(f\"{fact=}, {clause=}, {resolvents=}\") \n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully naive inference is taking all your clauses and just smashing them together to infer new clauses. For the `path` clauses, we get new multi edge step theorems. I freshen the variables in one part of the pair in kind of a hacky way. It isn't _wrong_ to insufficiently freshen, you just won't get the most general possible resolution. You have accidental equality constraints between the variables of the two clauses.\n",
    "Basically no one does fully naive inference. Usually they jump to the given clause algorithm, which removes some obvious redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(edge(?X_, ?Y_), edge(?Y_, ?Z_)) ⊢ (path(?X_, ?Z_),),\n",
       " (path(?X_, ?Y), edge(?Y, ?Y_), edge(?Y_, ?Z_)) ⊢ (path(?X_, ?Z_),)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freshen(t):\n",
    "    # this is both ugly and wrong. Whatever\n",
    "    if isinstance(t, Var):\n",
    "        return Var(t.name + \"_\")\n",
    "    elif isinstance(t, Fn):\n",
    "        return Fn(t.name, tuple(freshen(arg) for arg in t.args))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid term\")\n",
    "def freshen_clause(c):\n",
    "    return Clause(tuple(map(freshen,c.neg)), tuple(map(freshen, c.pos)))\n",
    "\n",
    "def naive_infer(clauses):\n",
    "    res = []\n",
    "    for c1 in clauses:\n",
    "        for c2 in clauses:\n",
    "            c2 = freshen_clause(c2)\n",
    "            # if c1 != c2: # an optimization\n",
    "            resolvents = computeResolvents(c1, c2)\n",
    "            res.extend(computeResolvents(c1, c2))\n",
    "    return res\n",
    "\n",
    "naive_infer(clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bits and Bobbles\n",
    "I ran out of steam before getting to anything too juicy today. But some comments\n",
    "\n",
    "- The given clause algorithm is a semi naive strategy for expanding your inferences.\n",
    "- Particular strategies of using resolution can give you datalog or prolog. Hypothetical/contextual datalog is implementable as a strategy. Other named strategies: hyper resolution . UR / unit resolution. set of support\n",
    "- The factoring rule is necessary to get a complete resolution prover. It compresses the literals inside a single clause.\n",
    "- I don't really think of resolution as a first order logic method. \n",
    "- Alpha renaming / variants. Variable names don't really matter and everything should be invariant to changing them.\n",
    "- term indexing. Discrimination tries, path indexes, fingerprinting\n",
    "- Subsumption. If you have `foo(X)` as a fact (implicitly `forall x, foo(x)`), it is stronger than any `foo(a)`. The `foo(a)` fact is redundant. When you derive a new fact, you should check if it is redundant with respect to already processed facts.\n",
    "- Paramodulation. Treat equality special. Use positive equalityt facts to rewrite inside other clauses. Superposition is taking term orderings into account. A contextual generalization of knuth bendix completion.\n",
    "- queries. We can make a special term that the prover loop is looking for stuff that unifies with. I am interetsed in non refutation theorem proving applications\n",
    "- the occurs check. On the other hand, note that `X = sin(X)` is not intuitively a problem (`X = pi n`). \n",
    "- nominal unification / lambda / miller\n",
    "- How do you implement unification efficiently? Interesting stuff on wiki page.\n",
    "\n",
    "Good reading: Handbook of automated reasoning. Harrison's automated reasoning Handbook. PyRes paper\n",
    "\n",
    "I'll start chucking snippets of functionality from blog posts into knuckledragger\n",
    "\n",
    "Natural notion of  <= isa subsumes. == is \"alpha equiv to\".\n",
    "hash of every var should be the same.\n",
    "Term orderings also have a natural <=\n",
    "\n",
    "alpha equiv is basically mgu with var permutations instead of substitution\n",
    "nominal\n",
    "\n",
    "\n",
    "\n",
    "If everything was ground it's a bit simpler. This is the case for propositional logic\n",
    "```\n",
    "{A} |- {B}   {B} |- {C}\n",
    "-------------------------\n",
    "        {A} |- {C}\n",
    "```\n",
    "\n",
    "When we have variables, we figure out if two literals are \"equal\" by seeing if they unify. Then we need to apply that unification everywhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def freevars(t):\n",
    "    if isinstance(t, Var):\n",
    "        return {t.name}\n",
    "    elif isinstance(t, Fn):\n",
    "        return set().union(*map(freevars, t.args))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid term\")\n",
    "\n",
    "def freshen(t):\n",
    "    # this is both ugly and wrong.\n",
    "    if isinstance(t, Var):\n",
    "        return Var(t.name + \"_\")\n",
    "    elif isinstance(t, Fn):\n",
    "        return Fn(t.name, tuple(freshen(arg) for arg in t.args))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid term\")\n",
    "def freshen_clause(c):\n",
    "    return Clause(map(freshen,c.neg), map(freshen, c.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Factoring feels kind of like a structural rule like weakening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/eprover/PyRes/blob/master/resolution.py\n",
    "def computePosFactors(clause):\n",
    "    res = []\n",
    "    for lit1 in clause.pos:\n",
    "        for lit2 in clause.pos: # redundant.\n",
    "            s = mgu(lit1,lit2)\n",
    "            if s == None:\n",
    "                continue\n",
    "            new_clause = Clause(tuple(subst(lit,s) for lit in clause.neg), tuple(subst(lit,s) for lit in clause.pos if lit != lit1))\n",
    "            res.append(new_clause)\n",
    "    return res\n",
    "\n",
    "def computeNegFactors(clause):\n",
    "    res = []\n",
    "    for lit1 in clause.neg:\n",
    "        for lit2 in clause.neg: # redundant.\n",
    "            s = mgu(lit1,lit2)\n",
    "            if s == None:\n",
    "                continue\n",
    "            new_clause = Clause(tuple(subst(lit,s) for lit in clause.neg if lit != lit1), tuple(subst(lit,s) for lit in clause.pos))\n",
    "            res.append(new_clause)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given clause algorithm is similar to semi naive evaluation.\n",
    "If starts with a set of unprocessed clauses and processes them one by one by finding all possible resolutions against the processed clauses. One tries to prune away redundancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prove(clauses):\n",
    "    unprocessed = set(clauses)\n",
    "    processed = set()\n",
    "    while len(unprocessed) >= 0:\n",
    "        new = []\n",
    "        clause = unprocessed.pop()\n",
    "        new.extend(computeFactors(clause))\n",
    "        for clause2 in processed:\n",
    "            new.extend(computeResolvents(clause, clause2))\n",
    "        processed.add(clause)\n",
    "        delta = processed.difference(new)\n",
    "        unprocessed.update(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_eq(self, other, perm):\n",
    "    match self:\n",
    "        case Var(x), Var(y):\n",
    "            if x in perm:\n",
    "                return perm[x] == y\n",
    "            elif y in perm_inv:\n",
    "                return perm_inv[y] == x\n",
    "            else:\n",
    "                perm.add(x, y)\n",
    "\n",
    "def __eq__(self,other, perm={}):\n",
    "    alpha_eq(self, other, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First order logic\n",
    "Resolution is presented as a classical first order logic prover, but I don't think it really is. I think it can be thought of as fairly generic principles of what it means to have inference rules.\n",
    "A clause is quite a bit / identical to a [sequent](https://en.wikipedia.org/wiki/Sequent). The negative literals are the things before the turnstile `|-` and the positive literals are the things after. Resolution is then seen as an instance of the famed [cut rule](https://en.wikipedia.org/wiki/Cut_rule) which is in turn something like [modus ponens](https://en.wikipedia.org/wiki/Modus_ponens)\n",
    "Logic programming has a similar confusion. `:-` is best thought of as the horizontal inference line rather than $\\rightarrow$. See The Logic of Logic Programming https://arxiv.org/abs/2304.13430 and Nadathur and Miller https://www.amazon.com/Programming-Higher-Order-Logic-Dale-Miller/dp/052187940X\n",
    "\n",
    "[First order logic](https://en.wikipedia.org/wiki/First-order_logic) has `and or implies not` but also predicates/relationships like `parent(adam, abel)` or `border(us, canada)`  and `forall` $\\forall$  `exists` $\\exists$ quantifiers. It's a pretty rich system capable of expressing lots of logical ideas about graphs, geometry, groups, sets, and is fairly amenable to automation (more so seemingly than sophisticated systems). It is conversely seen as fairly inexpressive. You may need to bolt on some pretty alarming axioms (like the axiom of specification) to get FOL to actually work for you as a foundation of mathematics.\n",
    "\n",
    "So the story goes, you can convert a pile of first order logic statements to [conjunctive normal form](https://en.wikipedia.org/wiki/Conjunctive_normal_form) (a giant AND of ORs). `A -> B` is turned into `~A \\/ B` and etc. Probably most interestingly, quantifiers are removed via [skolemization](https://en.wikipedia.org/wiki/Skolem_normal_form). A statement `\\forall x \\exists y, parent(y,x)` kind of is saying a similar thing to `forall x, parent(father(x), x)`. Note that similarly I could have done `forall x, parent(mother(x), x)` or `forall x, parent(someparent(x), x)` (really I should make a fresh function symbol and then prove that the fresh function symbvol is the same as some other defined notion). Operationally, you can push existentials through universals if you turn them into function symbols  depending on the thingsy ou pushed them though. Often these functions have some reasonable interpretation in terms of the things you're trying to model.\n",
    "\n",
    "Skolemization producers new formula that are equisatisfiable to the old ones. They are logically equivalent in the sense of being able to prove the skolemized formula from the old one, because the old one doesn't say that specifically your new invented symbols are the ones with the right properties. This all may be intertwinerd with axiom of choice.\n",
    "\n",
    "Becauswe we've pushed all the existentials to the front, now the formula only has top level quantifiers instead of nested complicated ones. We can strip off the explicit quantifier symbol  and replace it with a notion of variables vs constants/function symbols.\n",
    "\n",
    "This was all quite hand wavy. See The handbook of automated reasoning or harrison's handbook for more.\n",
    "\n",
    "Anyway, eventually you get to CNF. Now the basic inference steps are resolution and factoring (which is sort of resolving a clause on itself). These are complete\n",
    "\n",
    "\n",
    "\n",
    "It's kind of curious the distinction we make between FOL and other things. We think of FOL as a kind of logical framework in which we can talk about different mathematical ideas in a common infrastructure. But also FOL is kind of a very abstracted set theory on it's own. In metamath for example, first order logic is not that special compared to other things. Predicates are sort of like the sets of things they are provable on. Set theory comes about when we enable ourselves to reflect (comprehension) predicates into objects that we can manipulate and talk about.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To start a mini pyres\n",
    "\n",
    "idea: what about an isabelle style [] => []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fingerprinting https://link.springer.com/chapter/10.1007/978-3-642-31365-3_37\n",
    "\n",
    "def symcount(t:Term):\n",
    "    pass\n",
    "def varcount():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proof recording system\n",
    "proof_db = []\n",
    "def axiom(s):\n",
    "    proof_db.append((s, \"axiom\"))\n",
    "    return len(proof_db)\n",
    "def formula(s):\n",
    "    return proof_db[s][0]\n",
    "def factor(c):\n",
    "    f = compute_factor(formula(c))\n",
    "    proof_db.append((f, (\"factor\",c)))\n",
    "    return len(proof_db)\n",
    "def resolve(c1,c2):\n",
    "    r = compute_resolvent(formula(c1), formula(c2))\n",
    "    proof_db.append((r, (\"resolve\",c1,c2)))\n",
    "    return len(proof_db)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prolog using these pieces\n",
    "class Goal():\n",
    "    def __init__(self, goal_clause):\n",
    "        self.goal = goal_clause\n",
    "        self.goal = infer([goal], goal)  # we can start with refl.\n",
    "\n",
    "    def rule(self, clause):\n",
    "        # hmm. I do need to record?\n",
    "        compute_resolvent(self.goal, clause)\n",
    "\n",
    "    def erule(self, clause):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clause' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, lit1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mclause\u001b[49m\u001b[38;5;241m.\u001b[39mliterals):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lit2 \u001b[38;5;129;01min\u001b[39;00m clause\u001b[38;5;241m.\u001b[39mliterals[i:]:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lit1\u001b[38;5;241m.\u001b[39mneg \u001b[38;5;241m==\u001b[39m lit2\u001b[38;5;241m.\u001b[39mneg:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clause' is not defined"
     ]
    }
   ],
   "source": [
    "    for i, lit1 in enumerate(clause.literals):\n",
    "        for lit2 in clause.literals[i:]:\n",
    "            if lit1.neg == lit2.neg:\n",
    "                continue\n",
    "            s = mgu(lit1,lit2)\n",
    "            if s == None:\n",
    "                continue\n",
    "            new_clause = [Literal(lit.neg, subst(lit.term,s)) for lit in clause.literals if lit != lit1 and lit != lit2]\n",
    "            res.append(Clause(new_clause))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metitarski. What if I included arb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Fact():\n",
    "    ctx : tuple[Term, ...]\n",
    "    fact: Term\n",
    "class Rule():\n",
    "\n",
    "\n",
    "def hypo_datalog():\n",
    "    rules = []\n",
    "    facts = []\n",
    "    while True:\n",
    "        for rule in rules:\n",
    "            for fact in facts:\n",
    "                compute_resolvent(rule,fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Rule():\n",
    "    head: Term\n",
    "    body: tuple[Term, ...]\n",
    "\n",
    "def prolog():\n",
    "    rules = []\n",
    "    for rule in rules:\n",
    "        s = compute_resolvent(rule.head, goal[-1])\n",
    "        goal.extend[subst(rule.body, s)]\n",
    "\n",
    "# but how do I make the \"strategy\" nature self manifest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2863809388.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    case \"COMMA\"\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "toks = [\n",
    "    (\":-\", \"IMPLIES\"),\n",
    "    (\"\\\\.\", \"DOT\"),\n",
    "    (\"\\\\(\", \"LPAREN\"),\n",
    "    (\"\\\\)\", \"RPAREN\"),\n",
    "    (\"[a-zA-Z]+\", \"FN\"),\n",
    "    (\"[A-Z][a-zA-Z]*\", \"VAR\"),\n",
    "    (\",\", \"COMMA\"),\n",
    "    (\"\\\\s+\", \"SPACE\")\n",
    "]\n",
    "tokpat = re.compile(\"|\".join(f\"(?P<{name}>{pat})\" for pat, name in toks))\n",
    "def parse_rule():\n",
    "\n",
    "def parse_term(s):\n",
    "    match s.lastgroup:\n",
    "        case \"COMMA\":\n",
    "        \n",
    "        \n",
    "\n",
    "        case \"RPAREN\":\n",
    "            return Fn(name, args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lark_grammar = \"\"\"\n",
    "prog : rule*\n",
    "rule : term \":-\" term (\",\" term )* \".\" | term \".\"\n",
    "term = var | fn\n",
    "fn = IDENT \"(\" term (\",\" term)* \")\"\n",
    "var = VAR\n",
    "\n",
    "hyprule : \"{\" term* \"}\" \"|-\" term :- \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datalog():\n",
    "    rules = []\n",
    "    facts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literal selection\n",
    "Ordered resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@dataclass\n",
    "class Literal():\n",
    "    neg: bool\n",
    "    term:Term\n",
    "\n",
    "@dataclass\n",
    "class Clause():\n",
    "    literals: list[Literal]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! source ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion.choices[0].message.content\n",
    "chat_completion.json()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
