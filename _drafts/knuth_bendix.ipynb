{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "let rec termsize tm =\n",
    "  match tm with\n",
    "    Var x -> 1\n",
    "  | Fn(f,args) -> itlist (fun t n -> termsize t + n) args 1;;\n",
    "\"\"\"\n",
    "def termsize(tm):\n",
    "    match tm:\n",
    "        case (\"Var\", x):\n",
    "            return 1\n",
    "        case (\"Fn\", f, args):\n",
    "            return sum(map(termsize, args)) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "class Term:\n",
    "    pass\n",
    "@dataclass\n",
    "class Fn(Term):\n",
    "    f: str\n",
    "    args: Tuple[Term]\n",
    "\n",
    "@dataclass\n",
    "class Var(Term):\n",
    "    x: str\n",
    "\n",
    "def Function(fn):\n",
    "    def res(*args):\n",
    "        return Fn(fn, args)\n",
    "    return res\n",
    "def Vars(xs):\n",
    "    return [Var(x) for x in xs.split()]\n",
    "def Functions(fns):\n",
    "    return [Function(fn) for fn in fns.split()]\n",
    "\n",
    "import enum\n",
    "\n",
    "# traat\n",
    "# harrison\n",
    "# norvig\n",
    "# eli bendersky\n",
    "\n",
    "def unify(t1,t2):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cl.cam.ac.uk/~jrh13/atp/\n",
    "\n",
    "Knuth bendix + grobner\n",
    "Can we do it? It'd be cool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "let rec lexord ord l1 l2 =\n",
    "  match (l1,l2) with\n",
    "    (h1::t1,h2::t2) -> if ord h1 h2 then length t1 = length t2\n",
    "                       else h1 = h2 & lexord ord t1 t2\n",
    "  | _ -> false;;\n",
    "\"\"\"\n",
    "def lexord(ord, l1, l2):\n",
    "    match (l1, l2):\n",
    "        case ([h1,*t1], [h2, *t2]):\n",
    "            if ord(h1, h2): # yeah I dunno about this. Is this a faithful rep of ord\n",
    "                return len(t1) == len(t2)\n",
    "            else:\n",
    "                return h1 == h2 and lexord(ord,t1, t2)\n",
    "        case _:\n",
    "            return False\n",
    "\n",
    "lexord([1,5], [1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "let rec lpo_gt w s t =\n",
    "  match (s,t) with\n",
    "    (_,Var x) ->\n",
    "        not(s = t) & mem x (fvt s)\n",
    "  | (Fn(f,fargs),Fn(g,gargs)) ->\n",
    "        exists (fun si -> lpo_ge w si t) fargs or\n",
    "        forall (lpo_gt w s) gargs &\n",
    "        (f = g & lexord (lpo_gt w) fargs gargs or\n",
    "         w (f,length fargs) (g,length gargs))\n",
    "  | _ -> false\n",
    "\"\"\"\n",
    "def lpo_gt(w,s,t):\n",
    "    match (s,t):\n",
    "        case (_, (\"Var\", x)):\n",
    "            return s != t and x in fvt(s)\n",
    "        case ((\"Fn\", f, fargs), (\"Fn\", g, gargs)):\n",
    "            return any(lpo_ge(w, si, t) for si in fargs) or \\\n",
    "                all(lpo_gt(w, s, si) for si in gargs) and \\\n",
    "                (f == g and lexord(lambda s,t: lpo_gt(w,s,t), fargs, gargs) or \\\n",
    "                 w(f, len(fargs), g, len(gargs)))\n",
    "        case _:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size(t):\n",
    "    match t:\n",
    "        case Var(x):\n",
    "            return 1\n",
    "        case Fn(f, args):\n",
    "            return 1 + sum(map(size, args))\n",
    "\n",
    "def vars(t):\n",
    "    match t:\n",
    "        case Var(x):\n",
    "            yield x\n",
    "        case Fn(f, args):\n",
    "            for arg in args:\n",
    "                yield from vars(arg)\n",
    "from collections import Counter # a multiset type\n",
    "\n",
    "def var_comp_lte(t1,t2):\n",
    "    # We don't want to have more vars on lhs than rhs\n",
    "    c1 = Counter(vars(t1))\n",
    "    c2 = Counter(vars(t2))\n",
    "    for k in c2:\n",
    "        if c1[k] < c2[k]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbo2a(t1,t2):\n",
    "    if not isinstance(t2, Var):\n",
    "        return False\n",
    "    # check if t1 is iteerated functions symbol f over variable t2\n",
    "    if not isinstance(t1, Fn):\n",
    "        return False\n",
    "    fn = t1.f\n",
    "    def check(t):\n",
    "        if isinstance(t, Var):\n",
    "            return t == t2\n",
    "        elif isinstance(t, Fn):\n",
    "            return t.f == fn and len(t.args) == 1 and check(arg[0])\n",
    "        else:\n",
    "            raise ValueError(\"Not a term\")\n",
    "    return check(t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/kbo_test.p\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/kbo_test.p\n",
    "cnf(test, axiom, f = g).\n",
    "cnf(false, conjecture, true = false).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the input problem:\n",
      "  Axiom 1 (test): f = g.\n",
      "  Goal 1 (false): true = false.\n",
      "\n",
      "1. g -> f\n",
      "\n",
      "Ran out of critical pairs. This means the conjecture is not true.\n",
      "Here is the final rewrite system:\n",
      "  g -> f\n",
      "\n",
      "RESULT: CounterSatisfiable (the conjecture is false).\n"
     ]
    }
   ],
   "source": [
    "!twee /tmp/kbo_test.p --precedence g,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the input problem:\n",
      "  Axiom 1 (test): f = g.\n",
      "  Goal 1 (false): true = false.\n",
      "\n",
      "1. f -> g\n",
      "\n",
      "Ran out of critical pairs. This means the conjecture is not true.\n",
      "Here is the final rewrite system:\n",
      "  f -> g\n",
      "\n",
      "RESULT: CounterSatisfiable (the conjecture is false).\n"
     ]
    }
   ],
   "source": [
    "!twee /tmp/kbo_test.p --precedence f,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kbo(t1,t2):\n",
    "    if not var_comp_lte(t1,t2):\n",
    "        return True\n",
    "    w1 = size(t1)\n",
    "    w2 = size(t2)\n",
    "    if w1 > w2:\n",
    "        return True\n",
    "    elif w1 < w2:\n",
    "        return False\n",
    "    else:\n",
    "         if kbo2a(t1,t2):\n",
    "             return True\n",
    "         elif t2.f < t1.f:   #kbo2b\n",
    "            return True\n",
    "        elif: #kbo2c\n",
    "            \n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dedu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://link.springer.com/content/pdf/10.1007/3-540-17220-3_4.pdf How to choose the weights in the Knuth Bendix ordering -- ursula martin\n",
    "\n",
    "https://academic.oup.com/comjnl/article/34/1/2/427931 An Introduction to Knuthâ€“Bendix Completion Ajj dick\n",
    "\n",
    "https://link.springer.com/article/10.1007/s10817-006-9031-4  Things to Know when Implementing KBO\n",
    "\n",
    "We have a notion that simplifiers must terminate because terms get simpler until they can't\n",
    "\n",
    "\"size\" is a basic notion of complexity.\n",
    "\n",
    "In order to guarantee a rule with variables gets smaller, we can count the number of symbols in it. The number of pattern variables has to be getting smaller, or else the thing is getting bigger.\n",
    "\n",
    "`(X + 0) -> X` makes the term simpler\n",
    "\n",
    "`foo(bar(1,2,3,4,5,6,X)) -> biz(X,X)` is not definitely a simplification, because X might be huge. In a realistic situation, we might want to guard this rule by `size(X) < 3` or something.\n",
    "\n",
    "A slight extension is to give the symbols in the term weight.\n",
    "\n",
    "Another example is associating to the right. X + (Y + Z) -> (X + Y) + Z. This also obviously terminates. We can give lexicographic preference to left subtrees.\n",
    "\n",
    "\n",
    "Another example is getting flatter. The height is descreasing.\n",
    "\n",
    "distrbutivity is another common case. x*(y + z) -> x*y + x*z. This is getting bigger _and_ duplicating x. That's a big nono for most term orderings. But clearly foiling is terminating.\n",
    "\n",
    "A different system that is obviously terminating is stratified macro expansion. Macros can refer to previously defined macros. The terms however, may get very large and be increasing in size.\n",
    "f(X) -> bar(X,X) is not an issue.\n",
    "Cycles in the dependency graph\n",
    "\n",
    "We don't expect to be able to have a total ordering on terms with variables in them. But we do want our definition to have a well defined\n",
    "\n",
    "A primitive system that is obviously terminating are systems of the form `f(x,y,z,...) -> z` This is a view on the homeomorphic embedding relation.\n",
    "\n",
    "right ground systems\n",
    "\n",
    "Many functional programs are \"obviously\" terminating even if we don't think of them in these terms\n",
    "\n",
    "Negation normal form pushing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group axioms\n",
    "[0 + x == x,\n",
    " x + 0 == x,\n",
    " -x + x == 0,\n",
    " (x + y) + z == x + (y + z)]\n",
    "\n",
    "# inv(inv(x)) == x\n",
    "prove(-(-(x)) == x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about naive breadth first search:\n",
    "Separate into confluent terminating rules\n",
    "and naughty rules. (maude makes this disctinction but do so dynamically)\n",
    "\n",
    "Hash cons only things that are normalized with respect to current rules.\n",
    "run twee for a bit, extract oriented rules, confluence them (?)\n",
    "Use the others for search.\n",
    "\n",
    "TRS/SK90 Joachim Steinbach, Ulrich KÃ¼hler: Check your Ordering - termination proofs and open Problems, Technical Report SR-90-25, UniversitÃ¤t Kaiserslautern, 1990.\n",
    "TRS/D33 Nachum Dershowitz: 33 Examples of Termination, 1995 Proc. French Spring School of Theoretical Computer Science, LNCS 909, http://www.math.tau.ac.il/~nachumd/papers/printemp-print.pdf\n",
    "TRS/AG01 Thomas Arts, JÃ¼rgen Giesl: Termination of term rewriting using dependency pairs, 2000, http://dblp.uni-trier.de/rec/bibtex/journals/tcs/ArtsG00 http://verify.rwth-aachen.de/giesl/papers/ibn-97-46.ps\n",
    "SRS/Zantema 128 string rewriting termination problems collected by Hans Zantema (2004?). They include (as z027 .. z064) a set of one-rule termination problems by Alfons Geser (Habilitationsschrift, TÃ¼bingen, 2001) and possibly Winfried Kurth (Dissertation, Clausthal, 1990)\n",
    "\n",
    "disjunctive normal form example. Makes term bigger.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive\n",
    "\n",
    "def rw(t):\n",
    "    match t:\n",
    "        case (\"+\", 0, x):\n",
    "            return x\n",
    "        case x: \n",
    "            return (\"+\", 0, x)\n",
    "        case (\"+\", x, 0):\n",
    "            return x\n",
    "        case x:\n",
    "            return (\"+\", x, 0)\n",
    "        case (\"+\", (\"-\", x), x):\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def expand(t):\n",
    "    for (lhs,rhs) in rules:\n",
    "        yield from apply(lhs,rhs,t)\n",
    "        yield from apply(rhs,lhs,t)\n",
    "\n",
    "def prove(lhs,rhs):\n",
    "    lhsseen = set(lhs)\n",
    "    rhsseen = set(rhs)\n",
    "    while lhsseen & rhsseen == set():\n",
    "        for t in expand(lhsseen):\n",
    "            if t in rhsseen:\n",
    "                return True\n",
    "        for t in expand(rhsseen):\n",
    "            if t in lhsseen:\n",
    "                return True\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
