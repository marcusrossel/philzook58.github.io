The Resultant
-------------

The pole is the complex analyst's version of a delta function

$$\frac{1}{2\pi i}\frac{1}{\omega-\omega_{0}}\Longleftrightarrow\delta(\omega-\omega_{0})$$

The delta function is somewhat constructed by hand, whereas the pole is
more natrual. Hence the pole has more algebraicaly useful properties
than the delta function.

The matrxi of importance for eigenvalue problems is

$$L(\lambda)=A-\lambda I$$

For example the determinant of L is the charectristic polynomial whose
roots are the eigenvalues. An alternative matrix that seems equally
useful is the resultant

$$G(\lambda)=L^{-1}(\lambda)=\frac{1}{A-\lambda I}$$

The resultant occurs in a variety of scenarios, but its essence is a
plole grabber.

The determinant of this matrix is the reciprocol of the charecterstic
polynomial, so that isn't interesting. However, the trace is actually
useful.

Consider taking the trace in the energy basis

$$tr(G)=\sum_{n}<n|G|n>=\sum\frac{1}{\lambda_{n}-\lambda}$$

As we've mentioned, the pole is the complex analysts delta function, so
what we've constructed is essentially a sum of delta functions located
at the spectra.

$$\sum_{n}\delta(\lambda_{n}-\lambda)$$

We can use this function to find the number of states within a
particular energy range by taqking a contour integral around that energy
range.

The resultant occurs quite natrually during the Laplace or Fourier
transform of the Schrodinger equation

$$L=\partial_{t}-H$$

Hence the reference to is as being a green's function.

The density matrix
------------------

The desnity matrix is spriitually different from other matrices. It
corresponds to a state rather than a operator, however this state vector
happens to have two natrual indices. To some degree, I believe it is an
abuse of notation. However this mapping is useful in that we may build
denisty matrices out of operaztors.

The one particle density matrix can be constructed from the resultant,
which we know a great deal about. We take a contour integral around the
range of energies (Say less than the chemical potwntial) we want,
perhaps with a weighting factor (such as a boltzmann factor
$e^{-\beta(\lambda-\mu)})$

$$\rho=\oint Gw(\lambda)d\lambda$$

Chemical Potential and Reservoirs
---------------------------------

We may consider a system of N particles. We designate some of the states
as reservoir states (perhaps located in a giant box that has an
effective continuum of energies), which is filled up the the chemical
potential $\mu$. The act of creating a particle is changing the state
vector to one with a particle removed from the reservoir and placed into
the system. The annihilation operator is the opposite. We can then
remove the resrvoir states by creating a density matrix. We can restrict
operators to system oparators by using a projection operator which asks
whther the partile was in the system or the reservoir

Why is a green's function a green's function?
---------------------------------------------

$<0|\psi\psi|0>$

Pertubation series for one particle state.

Expanding around a state
------------------------

The ground state, or reservoir state.

Band diagrams
-------------

Bullshit?

Variational Hamiltonians
------------------------

Consider the function of the operator H

$$g(H)=tr(H_{0}-H)^{T}W(H_{0}-H)$$

W is a weighting matrix (for example $e^{-\beta H}$ or
$e^{-\beta H_{0}}$or $P_{H}$ the projection on the subspace of H
operator, or the resultant G, etc). H itself will be a function of
parameters $\{h\}$.

The idea is that you try to minimize this function to get the spectrum
to match as closely as possible.

$$g(H)\approx\sum(\lambda_{n0}-\lambda_{n})^{2}$$

One example of a variational hamiltonian is

$$H=\sum_{i,j}h_{ij}|i><j|$$

Where the indices run over some incomplete set of vectors.What we get
from this is the galerkin hamiltonian.

Another interesting possiblity is

$$H(\alpha')=\sum_{i,j}E^{(1)}|n^{(1)}><n^{(1)}|$$

Where the effective hamiltonian is reconstrcuted from some order (1st in
this case) or perturbation theory. We still have the effective coupling
parameter $\alpha'$ with which to minimize with respect to. We may also
weight this so that it works at a particulr energy scale (using a
resultant weighting $G(\Lambda)$ say). Hence the efftective paramter
$\alpha'(\alpha_{0},\Lambda)$. How renormalizy!

The best approximating harmonic oscillator may not be very close to the
zero perturbed best appoximating harmonic oscillator. How do we
reexpress creation and annihilation operators for one harmonic
oscillator in terms of another? Boguliobov transformation! Warps the
phase space ellipses

Since a hamiltonian implicitly defines and describes its eigenvectors,
what we are sort of doing is the traditional variational method in
parrallel. We simultaneously minimize under the constraint that the
eigenvectors must remain orthogonal. To get the same results, we must
choose a weighting such that the correctness of lower eigenvectors
dominates consideration of the higher ones in turn.

Of course, least squares is mostly bullshit. Its just easy. There is no
reason I could not choose as a simple extension

$$trConvex(H_{0}-H)$$

or trace

Envelopes and carriers
----------------------

The mathemtical idea behind envelopes and carriers is that we can
occasionally describe a vector (wavefunction) well by a factorrized form

$$w=e\otimes c$$

we consider the carrier wave to be somewhat irrelevant. and all the
interest to be on the behavior of the enevlope wave.

We can find such a decomposition by utilizing the SVD. Occasionally,
we'll find the behavior dominated by the first few singular vectors,
this is the situation where this idea is useful.

WKB does not quite fit into this picture since the carrier wave
($e^{iS})$ is not periodic. This is closer to FM.

$$\sin((\omega_{0}+\epsilon(t))t)$$

or

$$\sin(\omega t+\delta(t))$$

In real space, we can do this by breaking up the entire domain into
blocks

$$t=t'+nT$$

$$0<t'<T$$

$$n=0,1,2,3$$

Once we discretize this to $t'=l\Delta t$, the l index describes the
fast carrier space and the n index describes the slow envelope space.

Often we consider c-space to be a sinusuoidal function, but this is not
neccessary. An example of this is the bloch vector system. For bloch
vectors the carrier wave is something that sort of looks like atomic
orbitals, whereas the envelope space consists of an overlaying crystal
momentum oscillation. This is why the macroscopic behavior of crystals
is well described by the the behavior of the crystal momentum

Choosing a prciular carrier wave vector describes a linear subspaces. We
can find a new restrcited effective evolution operator within this
subspace. This works out to be appoximately a wave equation with the
group velicoty as the wave velocity

Bloch vectors and bethe scattering is related to birefringence. Taking
the evolute or involute of the energy surface may be interesting? (group
velocty sruface? )

Renomalization and multigrid
----------------------------

Multiaprticle matrices

External Potential matrix

$$V=V\otimes I\otimes I+I\otimes V\otimes I+I\otimes I\otimes V$$

Interaction (U is a sum of 2 kroncker producted terms)

$$$$

$$U=U\otimes I+I\otimes U+?$$

The kronecker notyation is insufficent to describe my needs. Maybe U
with a bracket connecting the pieces?

The point is that it crosses spaces.

$$U=u_{ijkl}\delta_{mn}+...$$

We may use the schur complement to partially solve a system.

Specifically in k-space. we may solve out the fastest eigenvectors. to
produce a new hamiltonian on a smaller grid

We may write this in terms of restriction and interpolation operators,
however they will not be as clean as the halving oprators which merely
average neighbors. Probably something more sinc esque.

Maybe the resitrction operator

$$R=U_{N-1}^{\dagger}\begin{array}{ccc}
1 & 0 & 0\\
0 & 1 & 0
\end{array}U_{N}$$

$\frac{(N-1)}{N}$ factor is floating around somewhere (scaling factor).
Also, if using DFT, fastest modes are actually in the middle (N/2)
somwhere since periodic.

Not as precise as schur complement. Maybe better is schur complement
$A_{N-1}-b^{T}d^{-1}c$ and then interpolate using $I=R^{\dagger}$

Full

$$R=R\otimes R\otimes R$$

$$I=I\otimes I\otimes I$$

How do R and I interact with the potentials U? Marginal operators,
effective vertices, etc.

I am not certain I have the rescaling part of renomralization

The fixed point of the operation?

Path integrals and partition functions.

Symmettry persistance into macroscale?

$$[H,S]=0$$

$$[R,S]=?$$

Waveguide Etendue
-----------------

Wvaeguide to large cavity to waveguide.

FOurier series - to kirchoff integral to foueir series is full transfer
function.

What if cavity is blackbody? Then we have well defined thermal noise,
bandwidth. Noisy coding theorem.

etendue is realted to density of states. The dAdA/r\^2 form
