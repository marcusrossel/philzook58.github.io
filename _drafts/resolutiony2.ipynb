{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground resolution\n",
    "Ordered Ground Resolution\n",
    "\n",
    "Ground paramodulation\n",
    "Ground superposition\n",
    "\n",
    "https://events.model.in.tum.de/mod23/lectures.html Jasmin Blanchettes lectures\n",
    "https://matryoshka-project.github.io/pubs/satur_report.pdf A Comprehensive Framework for\n",
    "Saturation Theorem Proving\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_size(t):\n",
    "        match t:\n",
    "            case (t1,args):\n",
    "                return 1 + sum(map, ground_size, args)\n",
    "def ground_kbo(t1,t2):\n",
    "    s1 = ground_size(t1)\n",
    "    s2 = ground_size(t2)\n",
    "    if s1 < s2:\n",
    "        return True\n",
    "    if s1 > s2:\n",
    "        return False\n",
    "    elif s1 == s2:\n",
    "        if t1[0] < t2[0]:\n",
    "            return True\n",
    "        elif t1[0] > t2[0]:\n",
    "            return False\n",
    "        elif t1[0] == t2[0]:\n",
    "            for i in range(1,len(t1)):\n",
    "                if t1[i] < t2[i]:\n",
    "                    return True\n",
    "                elif t1[i] > t2[i]:\n",
    "                    return False\n",
    "            return False\n",
    "    \n",
    "egraph = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Clause():\n",
    "    hyps: frozenset[Any]\n",
    "    concs: frozenset[Any]\n",
    "\n",
    "def maxlit(c : Clause):\n",
    "    return max(max(c.concs), max(c.hyps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideas about  hash consing.\n",
    "Could store more data in the nodes.\n",
    "numpy it or flatten it\n",
    "range queries with stdlib bisect\n",
    "We could uniquely label vars by depth first ordering. But then if they go in a frozenset, this becomes confusing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x) == f(f(x))=False\n",
      "f(x) == f(y)=True\n",
      "bar(x,y) == bar(x,x)=False\n",
      "bar(x,x) == bar(y,y)=True\n",
      "hash(bar(x,y))=-2698517946957590065 hash(bar(x,y))=-2698517946957590065\n",
      "set([ bar(x,x), bar(y,y), bar(y,x), bar(x,y) ])={bar(?y, ?x), bar(?x, ?x)}\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "@dataclass(frozen=True)\n",
    "class Term():\n",
    "    pass\n",
    "@dataclass(frozen=True)\n",
    "class Fn(Term):\n",
    "    name: str\n",
    "    args: tuple[Any, ...] = ()\n",
    "    def __repr__(self):\n",
    "        if len(self.args) == 0:\n",
    "            return self.name\n",
    "        return f\"{self.name}({', '.join(map(repr, self.args))})\"\n",
    "    def __eq__(self, other, perm=[]):\n",
    "        if not isinstance(other, Fn) or self.name != other.name or len(self.args) != len(other.args):\n",
    "            return False\n",
    "        for x,y in zip(self.args, other.args):\n",
    "            if not x.__eq__(y,perm):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class Var(Term):\n",
    "    name: str\n",
    "    def __repr__(self):\n",
    "        return \"?\" + self.name\n",
    "    def __eq__(self, other, perm=[]):\n",
    "        if not isinstance(other, Var):\n",
    "            return False\n",
    "        for x,y in perm:\n",
    "            if x == self.name:\n",
    "                return y == other.name\n",
    "            if y == other.name:\n",
    "                return x == self.name\n",
    "        perm.append((self.name, other.name))\n",
    "        return True\n",
    "    def __hash__(self):\n",
    "        # The name is not alpha invariant so can't naively be part of the hash\n",
    "        return 19\n",
    "\n",
    "def f(x):\n",
    "    return Fn(\"f\", (x,))\n",
    "def bar(x,y):\n",
    "    return Fn(\"bar\", (x,y))\n",
    "x,y,z = map(Var, \"xyz\")\n",
    "\n",
    "print(f\"{f(x) == f(f(x))=}\")\n",
    "print(f\"{f(x) == f(y)=}\")\n",
    "print(f\"{bar(x,y) == bar(x,x)=}\")\n",
    "print(f\"{bar(x,x) == bar(y,y)=}\")\n",
    "\n",
    "print(f\"{hash(bar(x,y))=} {hash(bar(x,y))=}\")\n",
    "\n",
    "print(f\"{set([ bar(x,x), bar(y,y), bar(y,x), bar(x,y) ])=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f(x) :- bar, biz(?X)."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lark\n",
    "from lark import v_args\n",
    "@dataclass(frozen=True)\n",
    "class Fact():\n",
    "    head: Fn\n",
    "    def __repr__(self):\n",
    "        return f\"{self.head}.\"\n",
    "@dataclass(frozen=True)\n",
    "class Rule():\n",
    "    head: Fn\n",
    "    body: tuple[Fn, ...]\n",
    "    def __repr__(self):\n",
    "        return f\"{self.head} :- {', '.join(map(repr, self.body))}.\"\n",
    "\n",
    "grammar = \"\"\"\n",
    "?start : decl* \n",
    "?decl :  fact | rule\n",
    "?fact : term \".\"\n",
    "?rule : term \":-\" term (\",\" term)* \".\"\n",
    "?term : NAME \"(\" term (\",\" term)* \")\" -> fn\n",
    "      | \"?\" NAME -> var\n",
    "      | NAME -> const\n",
    "%import common.CNAME -> NAME\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "\"\"\"\n",
    "class Transformer(lark.Transformer):\n",
    "    fn = v_args(inline=True)(lambda self, n, *a: Fn(n, a))\n",
    "    const = v_args(inline=True)(Fn)\n",
    "    var = v_args(inline=True)(Var)\n",
    "    fact = v_args(inline=True)(Fact)\n",
    "    rule = v_args(inline=True)(lambda self, head, *body: Rule(head, body))\n",
    "    start = list\n",
    "\n",
    "datalog_parser = lark.Lark(grammar, parser=\"lalr\", transformer=Transformer())\n",
    "\n",
    "datalog_parser.parse(\"f(x). f(x) :- bar, biz(?X).\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal?\n",
    "@dataclass(frozen=True)\n",
    "class Atom():\n",
    "    name:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "class SortedListWithLE:\n",
    "    def __init__(self):\n",
    "        self._list = []\n",
    "\n",
    "    def insert(self, value):\n",
    "        bisect.insort_left(self._list, value)\n",
    "\n",
    "    def search_le(self, value):\n",
    "        index = bisect.bisect_right(self._list, value)\n",
    "        if index:\n",
    "            return self._list[index - 1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# Example usage:\n",
    "sl = SortedListWithLE()\n",
    "sl.insert(5)\n",
    "sl.insert(3)\n",
    "sl.insert(7)\n",
    "sl.insert(1)\n",
    "sl.insert(4)\n",
    "sl.insert(6)\n",
    "sl.insert(9)\n",
    "\n",
    "print(sl.search_le(2))  # Output: 1\n",
    "print(sl.search_le(5))  # Output: 5\n",
    "print(sl.search_le(8))  # Output: 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prolog has all the bits and pieces. WHy can't I just use prolog as my loigcal framework?\n",
    "Prolog is a pretty powerful metalanguage. Bindings are going to stink.\n",
    "Amy Felty. Could also try using elpi\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'truth': True, 'Y': 'c'},\n",
       " {'truth': True, 'Y': 'b'},\n",
       " {'truth': True, 'Y': 'd'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.swi-prolog.org/pldoc/doc_for?object=section(%27packages/janus.html%27)\n",
    "import janus_swi as janus\n",
    "#janus.consult(\"/tmp/trs.pl\")\n",
    "janus.consult(\"path\", \"\"\"\n",
    "edge(a,b).\n",
    "edge(b,c).    \n",
    "edge(c,d).\n",
    "\n",
    ":- table path/2.\n",
    "path(X,Y) :- edge(X,Y).\n",
    "path(X,Y) :- edge(X,Z), path(Z,Y).\n",
    "\"\"\")\n",
    "#ans = janus.query_once(\"normal_form([f(x) ==> g(x)], f(x), _Res), term_to_list(_Res,Res).\")\n",
    "#ans['Res']\n",
    "list(janus.query(\"path(a,Y).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "janus.consult(\"sequent\", \"\"\"\\\n",
    "% unify with occurs check\n",
    "theorem(refl, [], A = A, assume). % name, hyps, concs, reason\n",
    "              \n",
    "cnf(refl,axiom,[A = A]). % this basically is what tptp _is_\n",
    "\n",
    "% could reify stuff too. The sequent becomes a clause.\n",
    "% A == A.            \n",
    "              \n",
    "% modus takes in the _names_ of two theorems and returns a new theorem.\n",
    "modus(a,b,X) :- var(X), theorem(a, S, C, _), theorem(b, C, D, _), gensym(X), asserta(theorem(X, S, D, modus(a,b))). \n",
    "              % ammusingly call on the reason would basically prove the thing again.\n",
    "reflect(C) :- C, gensym(X), asserta(theorem(X,[],C)).\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
