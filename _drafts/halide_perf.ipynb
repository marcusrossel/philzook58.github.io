{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what would a minimal tensor compiler, scheduling guy look like?\n",
    "I need to output C++ code / Cuda / C++ simd ionstrinsics\n",
    "Oleg style C\n",
    "\n",
    "Could dynlink in the kernel. Or is it easier to just subprocess it?\n",
    "use that pytorch compile thing https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html\n",
    "https://cppyy.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Ideas:\n",
    "Blur\n",
    "Will melt - deform, \n",
    "wave\n",
    "heat\n",
    "reaction diffusion\n",
    "coulomb\n",
    "polybench problems?\n",
    "\n",
    "Arguably, computer perf is good for the environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(body):\n",
    "    return \"int main(){\" + body + \"return 0;}\"\n",
    "\n",
    "def type_of_shape(shape):\n",
    "    if len(shape) == 1:\n",
    "        return \"vector<int>\"\n",
    "    else:\n",
    "        return \"vector<vector<int>>\"\n",
    "\n",
    "def numpy_const(x):\n",
    "     return f\"{type_of_shape(x.shape)} {x.name} = {x.to_string(\"\n",
    "\n",
    "def matrix_multiply(a,b):\n",
    "     = a.shape\n",
    "     = b.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.31046626,  0.65844833,  0.07906275,  1.9617434 ,  1.42294726,\n",
       "         0.20204498,  0.40687659,  0.67967967, -0.00870005],\n",
       "       [ 3.54828591,  2.34538197,  1.96419394,  5.37431379,  3.33590376,\n",
       "        -0.35761729,  1.02769102,  1.11851864, -0.26513445],\n",
       "       [ 3.62105505,  3.27176744,  1.72605773,  1.19710883, -1.33067401,\n",
       "        -0.06654727, -1.01015221, -2.05987732, -2.42009655],\n",
       "       [ 3.4558572 ,  3.17985693,  0.49590552, -0.97296426, -2.69173456,\n",
       "         0.80930476,  1.9448902 ,  0.4162344 ,  1.06708111],\n",
       "       [ 0.57190069,  1.78356123, -1.51150129, -1.48969576,  1.1230824 ,\n",
       "         2.50065244,  3.24586681,  3.49688147,  3.71579744],\n",
       "       [ 0.88945686,  4.93068064,  0.60081222, -2.11282168,  1.36769066,\n",
       "         2.35703195,  0.41602892,  0.7976928 ,  0.03607092],\n",
       "       [ 0.66529984,  2.29259899,  0.81820352,  0.40120943,  1.66383995,\n",
       "        -0.56748654, -0.60277451,  2.2396351 ,  0.91317627],\n",
       "       [ 0.66636054, -0.10556659, -0.32316119,  0.95568744,  1.23081266,\n",
       "        -2.90894993, -1.28331082,  2.88038446,  2.00651862],\n",
       "       [ 1.96458533,  2.28375555,  0.9000126 ,  0.98802625, -0.03171931,\n",
       "        -3.40004844, -2.5444537 ,  1.00855292,  1.48019104]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "img = np.random.randn(10,10)\n",
    "\n",
    "def blurx(x):\n",
    "    return x[1:,:] + x[:-1,:]  \n",
    "def blury(x):\n",
    "    return x[:,1:] + x[:,:-1]  \n",
    "    #return np.convolve(x, [0.1, 0.8, 0.1], mode='same')\n",
    "img\n",
    "blury(blurx(img))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "I should probably know what it is I want to do manually first\n",
    "benchamrking infra... hmm.\n",
    "https://github.com/google/benchmark\n",
    "https://github.com/google/benchmark/blob/main/docs/user_guide.md\n",
    "https://github.com/google/benchmark/blob/main/docs/tools.md compare\n",
    "\n",
    "https://quick-bench.com/\n",
    "https://perfbench.com/\n",
    "https://github.com/chronoxor/CppBenchmark\n",
    "https://github.com/sharkdp/hyperfine\n",
    "\n",
    "https://ashvardanian.com/posts/google-benchmark/\n",
    "\n",
    "Oh it outputs json or scv. hmm\n",
    "https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/54db51700fabe094cbf7f11f5195d2bd/benchmark.ipynb\n",
    "pytorch benchmark\n",
    "timeit.Timer\n",
    "torch.utils.benchamrk.TImer\n",
    "Callgrind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/bench.cpp\n"
     ]
    }
   ],
   "source": [
    "%%file /tmp/bench.cpp\n",
    "#include <benchmark/benchmark.h>\n",
    "\n",
    "static void BM_StringCreation(benchmark::State& state) {\n",
    "  for (auto _ : state)\n",
    "    std::string empty_string;\n",
    "}\n",
    "// Register the function as a benchmark\n",
    "BENCHMARK(BM_StringCreation);\n",
    "\n",
    "// Define another benchmark\n",
    "static void BM_StringCopy(benchmark::State& state) {\n",
    "  std::string x = \"hello\";\n",
    "  for (auto _ : state)\n",
    "    std::string copy(x);\n",
    "}\n",
    "BENCHMARK(BM_StringCopy);\n",
    "\n",
    "BENCHMARK_MAIN();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23T11:57:08-04:00\n",
      "Running /tmp/mybenchmark\n",
      "Run on (8 X 3900 MHz CPU s)\n",
      "CPU Caches:\n",
      "  L1 Data 48 KiB (x4)\n",
      "  L1 Instruction 32 KiB (x4)\n",
      "  L2 Unified 512 KiB (x4)\n",
      "  L3 Unified 8192 KiB (x1)\n",
      "Load Average: 2.59, 2.10, 1.96\n",
      "***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Benchmark                  Time             CPU   Iterations\n",
      "------------------------------------------------------------\n",
      "BM_StringCreation       3.53 ns         3.53 ns    189533532\n",
      "BM_StringCopy           8.32 ns         8.32 ns     81841079\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "g++ /tmp/bench.cpp -std=c++11 -isystem ~/Downloads/benchmark/include \\\n",
    "  -L ~/Downloads/benchmark/build/src -lbenchmark -lpthread -o /tmp/mybenchmark\n",
    "/tmp/mybenchmark # --benchmark_out_format=json --benchmark_out=/tmp/bench.json\n",
    "# compare.py benchmarks /tmp/mybenchmark /tmp/mybenckmark2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Halide\n",
    "https://halide-lang.org/tutorials/\n",
    "\n",
    "\n",
    "- Hydride\n",
    "- Halide\n",
    "\n",
    "- SpEQ - http://www.paramathic.com/wp-content/uploads/2024/04/REV_PLDI_rev2.pdf\n",
    "- Exo: https://dl.acm.org/doi/abs/10.1145/3519939.3523446\n",
    "- Mosaic: https://manya-bansal.github.io/papers/pldi23main-p107-final.pdf\n",
    "\n",
    "- taco\n",
    "- glenside\n",
    "- mlir\n",
    "- \n",
    "Maaz Bin Safeer Ahmad, Alexander J Root, Andrew Adams, Shoaib Kamil, and Alvin Cheung. Vector instruction selection for digital signal processors using program synthesis.\n",
    "\n",
    "Sebastian Buchwald, Andreas Fried, and Sebastian Hack. Synthesizing an instruction selection rule library from semantic specifications.\n",
    "\n",
    "Yishen Chen, Charith Mendis, Michael Carbin, and Saman Amarasinghe. Vegen: a vectorizer generator for simd and beyond\n",
    "\n",
    "Zhengyang Liu, Stefan Mada, and John Regehr. Minotaur: A simd-oriented synthesizing superoptimizer\n",
    "\n",
    "Alexander J Root, Maaz Bin Safeer Ahmad, Dillon Sharlet, Andrew Adams, Shoaib Kamil, and Jonathan Ragan-Kelley. Fast instruction selection for fast digital signal processing.\n",
    "\n",
    "Alexander James Root. Optimizing Vector Instruction Selection for Digital Signal Processing. PhD thesis, Massachusetts Institute of Technology, 2022\n",
    "\n",
    "Samuel Thomas and James Bornholt. Automatic generation of vectorizing compilers for customizable digital signal processors. 2024.\n",
    "\n",
    "Alexa VanHattum, Rachit Nigam, Vincent T Lee, James Bornholt, and Adrian Sampson. Vectorization for digital signal processors via equality saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file /tmp/halide.cpp\n",
    "\n",
    "Func blur_3x3(Func input) {\n",
    "  Func blur_x, blur_y;\n",
    "  Var x, y, xi, yi;\n",
    "\n",
    "  // The algorithm - no storage or order\n",
    "  blur_x(x, y) = (input(x-1, y) + input(x, y) + input(x+1, y))/3;\n",
    "  blur_y(x, y) = (blur_x(x, y-1) + blur_x(x, y) + blur_x(x, y+1))/3;\n",
    "\n",
    "  // The schedule - defines order, locality; implies storage\n",
    "  blur_y.tile(x, y, xi, yi, 256, 32)\n",
    "        .vectorize(xi, 8).parallel(y);\n",
    "  blur_x.compute_at(blur_y, x).vectorize(x, 8);\n",
    "\n",
    "  return blur_y;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perf Ninja\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
